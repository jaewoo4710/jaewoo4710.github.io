---
title:  "Day 11"
excerpt: "Code States Week3 Day11"

toc: true
toc_sticky: true

categories:
  - Code States
tags:
  - Week 3
  - Reivew
last_modified_at: 2020-09-16T08:06:00-05:00
---


# 오늘 배운 것 
 통계의 가설 검증 방법 중의 하나인 T-test 활용. 내가 아는것을 정리 해보자면, T-test는 일단 하나의 파라미터에 대해서 가설 검증을 하는 것이라고 알고 있다. **Degree of freedom** 에 대해서 좀 유념을 해야 할 것 같다.
대부분의 내용은 이미 거의 다 아는 것이었고, 내가 알고있는 바를 다시 한 번 확인해보는 시간이었다. Python 에서는 `from scipy import stats` 를 사용하여 1 sided t-test or 2 sided t-test를 활용할 수 있다.

# 활용
공공기관 데이터 세트의 활용
```py
trees = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/seoul_tree/seoul_tree.txt', sep = '\t', skiprows = 1, encoding='utf-8')

trees = trees.replace({'-':0})

trees = trees[1:len(trees)-2] # 1st row and last 2 row drop

trees.head(2)

```
> 생각보다 DataFrame 을 **slicing** 하기가 할 때마다 까다롭다. 그래서, `loc`이라는 메서드와 `iloc`이라는 메서드를 통해서 잘 활용해보자.

```py
# object to numeric
trees.iloc[:,2:] = trees.iloc[:,2:].apply(lambda x: x.str.replace(',','').atstype('float'))
trees.head(2)

```
> 실제로 `iloc`을 통해서 **slicing** 을 적용 할 수 있었다. 데이터의 값이 **object** 일 경우, `replace` 를 통해서 숫자의 단위 점을 없애게 만들어준다. 지금까지는 `str.strip()`, `str.replace()`를 
사용 해보았다. 데이터 값의 데이터 형의 변환은 `astype()`으로 가능하다.

```py
df = trees.sample(n = 10, random_state = 30).reset_index()
df.head(2)
print(trees['양버즘나무'].mean(), df['양버즘나무'].mean())

from scipy import stats

stats.ttest_1samp(df['양버즘나무'], trees['양버즘나무'].mean())
```
> `df.sample` 이 주어진 데이터 세트 (df) 내에서 샘플링을 하는 방법이다. `stats.ttest_1samp(데이터 세트, 목표값)`은 가장 간단히 parameter 하나에 대한 t-test를 하는 방법이고, 결과값으로 t-stat value
와 p-value가 같이 구해진다. 

```py
price = pd.read_csv('price.csv' , engine = 'python', encoding = 'euc-kr')
data = price.loc[~price['품목 이름'].str.contains('돼지고기|쇠고기')]
mart = data.loc[data['시장유형 구분(시장/마트) 이름'] == '대형마트'].reset_index()
market = data.loc[data['시장유형 구분(시장/마트) 이름'] == '전통시장'].reset_index()
```
> `read_csv(, encoding = 'euc-kr')` 한국 데이터를 사용한다면, 자주 겪게 될 문제이다. 그냥 외워놓자. `df.loc[~df[''].str.contains('word')]` 한 번 썼더니 몸이 기억한다.
특정 문자가 없는 값을 빼고 나머지 전체 데이터 프레임을 얻는 방법이다. `mart = data.loc[data['시장유형 구분(시장/마트) 이름'] == '대형마트'].reset_index()` 여기서 내가 쓴 방법은, `loc[condition]`
인데 그 다음에 `reset_index()` 를 통해서 데이터 프레임으로 변환하는 방법을 사용했다. *지금 생각해보니 `groupby().apply.reset_index()` 를 통해서도 가능하지 않을까 싶다. 한 번에 가능했을 수도 있겠다.*

```py
prices = pd.concat([mart, market], axis=1)
prices.columns = ['마트이름', '품목이름', '마트가격', '시장이름', '품목', '시장가격']
prices = prices.drop('품목', axis = 1)
prices.head(2)
diff_price = pd.DataFrame(prices.groupby('품목이름')['시장가격', '마트가격'].mean()).reset_index()
diff_price.head(2)
diff_price['가격차이'] = abs(diff_price['마트가격'] - diff_price['시장가격'])
```
> 지금보니깐 떼었다가 붙였다가, `groupby().apply.reset_index()` 를 사용하면 이 과정이 아무것도 필요 없지 않을까?

```py
price = pd.read_csv('price_all.csv' , engine = 'python', encoding = 'euc-kr')
res = price.groupby("자치구 이름").apply(lambda x:x['가격(원)'].groupby(x['시장유형 구분(시장/마트) 이름']).mean()).reset_index()
res.head()
```
> `price.groupby("자치구 이름").apply(lambda x:x['가격(원)'].groupby(x['시장유형 구분(시장/마트) 이름']).mean()).reset_index()` 내가 기대한것은 row : 자치구 이름, column : 시장유형
그리고 값으로 평균 가격이 되길 바랬으나 그렇지 못했다.

```py
pv = res.pivot_table(values = '가격(원)', index = '자치구 이름', columns = '시장유형 구분(시장/마트) 이름')
pv = pv.dropna()
pv.head(2)
```
> 그래서 다시 한 번 pivot table 을 통해서 원하는 바를 이루어 냈다. 원래 이걸 하면서, mean 의 값을 자꾸 `stats.ttest_ind()` 에 자꾸 적용시켜서 얼마나 많은 시간을 여기에 날렸는지 모르곘다.
`stats.ttest_ind()` 에 input 되는 데이터는 data series든 data frame 이 되어야 한다. 

```py
pv['pvalue'] = price.groupby('자치구 이름').apply(lambda x: stats.ttest_ind(x[x["시장유형 구분(시장/마트) 이름"] == "대형마트"]['가격(원)'], 
                                                        x[x["시장유형 구분(시장/마트) 이름"] == "전통시장"]['가격(원)'])[1])
```
> 전체 데이터 세트에서 앞에서 그룹화 한 것처럼 **자치구 이름**, **시장유형 구분** 의 각 각 가격탭을 끌어와서 `stats.ttest_ind()`를 적용 시켜야 했던 것이다.
이 과정을 통해서 많이 느낀 사실은, 데이터 세트를 필터링 시킬려고 먼저 접근하기보다는, 필요한 정보를 `groupby` 해서 원하는 정보를 잘 처리해서 사용하거나, 잘 처리해서 데이터 전처리에 이용하는 것이다!
이걸 항상 명심하자!





